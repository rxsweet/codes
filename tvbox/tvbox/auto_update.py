#å‚è€ƒ
#https://github.com/yub168/myTvbox/tree/master
#https://github.com/loopool/fan/tree/main
#æœ€å…¨çš„å¸¸ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤§å…¨https://blog.csdn.net/weixin_40583388/article/details/78458610
# -*- coding: utf-8 -*-
import requests
import json
import re
import os
import json5
import base64
from Crypto.Cipher import AES
from tqdm import tqdm
import threading
from datetime import datetime   #æ—¶é—´
import hashlib
import configparser		#https://blog.csdn.net/happyjacob/article/details/109346625

#rx = {"key":"å„¿ç«¥ä¹å›­","name":"å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","searchable":0,"quickSearch":0,"changeable":0,"ext":"http://d.kstore.dev/download/4901/tvbox/json/å„¿ç«¥ä¹å›­.json"}
rx = {"key":"å„¿ç«¥ä¹å›­","name":"å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","searchable":0,"quickSearch":0,"changeable":0,"ext": "./json/å„¿ç«¥ä¹å›­.json"}

#https://github.moeyy.xyz/
#å°†jsonæ•°æ®è½¬æˆå­—ç¬¦ä¸²ï¼Œhttps://blog.csdn.net/qq_46293423/article/details/105785007
#content = json.dumps(config,ensure_ascii=False)
#config = re.sub(r'"https://raw.githubusercontent.com/n3rddd/N3RD/master/JN/','"./',content)
#å°†å­—ç¬¦ä¸²è½¬æˆjsonæ•°æ®ï¼Œhttps://blog.csdn.net/qq_46293423/article/details/105785007
#config = json.loads(config)


list={
    'feimao':'http://www.é¥­å¤ªç¡¬.com/jm/jiemi.php?url=http://è‚¥çŒ«.com',
    'fan':"http://www.é¥­å¤ªç¡¬.com/tv",
    'n3rddd_lem':'https://raw.githubusercontent.com/n3rddd/N3RD/refs/heads/master/JN/lem.json',
    'n3rddd_js':'https://raw.githubusercontent.com/n3rddd/N3RD/master/JN/lemj.json',
    'n3rddd_vod':'https://raw.githubusercontent.com/n3rddd/N3RD/master/JN/lemvod.json',
    'PowerTechott2':'https://raw.githubusercontent.com/PowerTechott/baotv/refs/heads/main/bh2',
    "æœˆå…‰çº¿è·¯1":"https://raw.githubusercontent.com/guot55/yg/main/boxåŸ.json",
    "æ½‡æ´’çº¿è·¯":"https://raw.githubusercontent.com/PizazzGY/TVBox/main/api.json",
    'å°è€Œç¾':'https://raw.githubusercontent.com/xixifree/xxbox/master/0821.json',
    "dxawi":"https://raw.githubusercontent.com/dxawi/0/refs/heads/main/0.json",
    'é¦™é›…æƒ…':'https://raw.githubusercontent.com/xyq254245/xyqonlinerule/main/XYQTVBox.json',
    "qq1719248506":"https://raw.githubusercontent.com/qq1719248506/Video-interface/refs/heads/main/config.json",
    "anaer":"https://raw.githubusercontent.com/anaer/Meow/refs/heads/main/meow.json",
    "aaabbbxu1":"https://raw.githubusercontent.com/aaabbbxu/tvboxs/refs/heads/main/boxs.json",
    "è«åçš„æ‚²ä¼¤":"https://raw.githubusercontent.com/Dong-learn9/TVBox-zyjk/refs/heads/main/tvbox2.json",
    "æ¬§æ­Œ":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/æ¬§æ­Œ/api.json",
    "æ‘¸é±¼å„¿":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/æ‘¸é±¼å„¿/api.json",
    "å¤©å¤©å¼€å¿ƒ":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/å¤©å¤©å¼€å¿ƒ/api.json",
    "drpy_t3":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/drpy_t3/api.json",
    "PG_api":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/PG/api.json",
    "PG_jsm":"https://raw.githubusercontent.com/ls125781003/tvboxtg/refs/heads/main/PG/jsm.json",
    'gao':'https://raw.githubusercontent.com/gaotianliuyun/gao/master/js.json',
    'bobyang3':'https://raw.githubusercontent.com/bobyang3/tvbox/refs/heads/own/jsm.json',
    'è¿è¾“è½¦':'https://weixine.net/ysc.json',
    "å–µå½±è§†":"http://meowtv.top/tv",
    "FongMi_fish2018":"http://www.fish2018.us.kg/z/FongMi.json",
    "liucn":"https://raw.liucn.cc/box/m.json",
    'rx_js':'https://rxsub.eu.org/tvbox/js.json',
  }

def list_rm(urlList):#åˆ—è¡¨å»é‡
    begin = 0
    rm = 0
    length = len(urlList)
    print(f'\n-----å»é‡å¼€å§‹-----\n')
    while begin < length:
        proxy_compared = urlList[begin]
        begin_2 = begin + 1
        while begin_2 <= (length - 1):
            if proxy_compared == urlList[begin_2]:
                urlList.pop(begin_2)
                length -= 1
                begin_2 -= 1
                rm += 1
            begin_2 += 1
        begin += 1
    print(f'é‡å¤æ•°é‡ {rm}\n-----å»é‡ç»“æŸ-----\n')
    print(f'å‰©ä½™æ€»æ•° {str(len(urlList))}\n')
    return urlList
    
def saveList(configList,file_addr):#ä¿å­˜æ–‡ä»¶
  
    if configList:
        print('ä¿å­˜' + file_addr + 'æ–‡ä»¶')
        file=open(file_addr,"w")
        file.write('\n'.join(configList))
        file.close()
        print('æŠ“å–æ—¶é—´ï¼š\t',datetime.now())

def saveConfig(customConfig,json_addr):#ä¿å­˜jsonæ–‡ä»¶
    if customConfig:
    # é…ç½®customConfigåŠå†™å…¥æ–‡ä»¶
        print('ä¿å­˜é…ç½®' + json_addr)
        with open(json_addr, "w",encoding='utf-8') as file:
        # ä½¿ç”¨json.dumpå°†æ•°æ®å†™å…¥æ–‡ä»¶
            json.dump(customConfig,file,indent=2,ensure_ascii=False)
            print('æŠ“å–æ—¶é—´ï¼š\t',datetime.now())

def getUrl_200(url): #æ£€æµ‹ç½‘ç«™æ˜¯å¦å¯ç”¨ï¼ˆå¯åœ¨å…¶ä¸­æ·»åŠ ç”µå½±ç½‘çš„ç‰¹å¾ç ï¼‰,å¯ç”¨è¿”å›False
    try:
        r=requests.get(url, timeout=3.0)
        if r.status_code==200:
            return False
        else:
            return True
    except Exception as e: 
        return True

class Js:#get js

    def down_libs(libs_addr):#ä¸‹è½½jsåº“æ–‡ä»¶
        nowtime = datetime.now()
        if nowtime.day%2 == 0:#é…åˆæ¯å‘¨æ›´æ–°tvboxï¼Œå°±ç›¸å½“äºåŠæœˆæ›´æ–°ä¸€æ¬¡
            #ä¸‹è½½åº“æ–‡ä»¶
            drpy_libs = requests.get('https://api.github.com/repos/n3rddd/N3RD/contents/JN/dr_py/libs/?ref=master').json()
            for lib in drpy_libs:
                libfile_addr = libs_addr + lib['name']
                response = requests.get(lib['download_url'])
                with open(libfile_addr, "wb") as f:
                    f.write(response.content)

    def getUrl_signJs(url): #æ£€æµ‹ç½‘ç«™æ˜¯å¦å¯ç”¨ï¼ˆå¯åœ¨å…¶ä¸­æ·»åŠ ç”µå½±ç½‘çš„ç‰¹å¾ç ï¼‰,å¯ç”¨è¿”å›False
        signs = ['ç”µå½±','ç”µè§†å‰§','è¿ç»­å‰§','å‰§åœº','éŸ©å‰§','ç»¼è‰º','åŠ¨æ¼«','ç¾å‰§','çƒ­æ’­','ä¸Šæ˜ ','å›½äº§','æ¸¯å°','é›»å½±','é›»è¦–åŠ‡','ç¶œè—','å‹•æ¼«']
        try:
            r=requests.get(url, timeout=5.0)
            if r.status_code==200:
                #return False
                for sign in signs:
                    if sign in r.text:
                        return False
                return True
            else:
                return True
        except Exception as e: 
            return True

    def get_ilive_js(site,jsList,bar,goodlist,bad):#åœ¨jsçš„æ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ°ç”µå½±ç½‘ç«™
        ilive ={'name':'','url':''}
        try:
            r=requests.get(site['ext'], timeout=5.0)
            if r.status_code==200:
                content = r.text
                host = None
                if content:
                    if 'quickSearch: 0' not in content and 'quickSearch:0' not in content:
                        content1 = re.sub('// host:','del content',content)
                        host = re.findall(r"host:'(.*?)',", content1)
                        if host:
                            if Js.getUrl_signJs(host[0]):
                                #print('ç§»é™¤ï¼š'+str(host[0]))
                                jsList.remove(site)
                                bad.append(site)
                            else:
                                ilive['name'] = site['name']
                                ilive['url']= host[0]
                                goodlist.append(ilive)
                        else:
                            host = re.findall(r"host: '(.*?)',", content1)
                            if host:
                                if Js.getUrl_signJs(host[0]):
                                    #print('ç§»é™¤ï¼š'+str(host[0]))
                                    jsList.remove(site)
                                    bad.append(site)
                                else:
                                    ilive['name'] = site['name']
                                    ilive['url']= host[0]
                                    goodlist.append(ilive)
                            else:
                                host = re.findall(r'host: "(.*?)",', content1)
                                if host:
                                    if Js.getUrl_signJs(host[0]):
                                        #print('ç§»é™¤ï¼š'+str(host[0]))
                                        jsList.remove(site)
                                        bad.append(site)
                                    else:
                                        ilive['name'] = site['name']
                                        ilive['url']= host[0]
                                        goodlist.append(ilive)
                                        
                                else:
                                    host = re.findall(r'"host": "(.*?)",', content1)
                                    if host:
                                        if Js.getUrl_signJs(host[0]):
                                            #print('ç§»é™¤ï¼š'+str(host[0]))
                                            jsList.remove(site)
                                            bad.append(site)
                                        else:
                                            ilive['name'] = site['name']
                                            ilive['url']= host[0]
                                            goodlist.append(ilive)
                                    else:
                                        #print('æœªæœç´¢åˆ°jsæ–‡ä»¶ä¸­çš„urlåœ°å€,ç§»é™¤ï¼š'+str(site['ext']))
                                        jsList.remove(site)
                                        bad.append(site)
                    elif 'filterable:1' in content or 'filterable: 1' in content:
                        content1 = re.sub('// host:','del content',content)
                        host = re.findall(r"host:'(.*?)',", content1)
                        if host:
                            if Js.getUrl_signJs(host[0]):
                                #print('ç§»é™¤ï¼š'+str(host[0]))
                                jsList.remove(site)
                                bad.append(site)
                            else:
                                ilive['name'] = site['name']
                                ilive['url']= host[0]
                                goodlist.append(ilive)
                        else:
                            host = re.findall(r"host: '(.*?)',", content1)
                            if host:
                                if Js.getUrl_signJs(host[0]):
                                    #print('ç§»é™¤ï¼š'+str(host[0]))
                                    jsList.remove(site)
                                    bad.append(site)
                                else:
                                    ilive['name'] = site['name']
                                    ilive['url']= host[0]
                                    goodlist.append(ilive)
                            else:
                                host = re.findall(r'host: "(.*?)",', content1)
                                if host:
                                    if Js.getUrl_signJs(host[0]):
                                        #print('ç§»é™¤ï¼š'+str(host[0]))
                                        jsList.remove(site)
                                        bad.append(site)
                                    else:
                                        ilive['name'] = site['name']
                                        ilive['url']= host[0]
                                        goodlist.append(ilive)
                                        
                                else:
                                    host = re.findall(r'"host": "(.*?)",', content1)
                                    if host:
                                        if Js.getUrl_signJs(host[0]):
                                            #print('ç§»é™¤ï¼š'+str(host[0]))
                                            jsList.remove(site)
                                            bad.append(site)
                                        else:
                                            ilive['name'] = site['name']
                                            ilive['url']= host[0]
                                            goodlist.append(ilive)
                                    else:
                                        #print('æœªæœç´¢åˆ°jsæ–‡ä»¶ä¸­çš„urlåœ°å€,ç§»é™¤ï¼š'+str(site['ext']))
                                        jsList.remove(site)
                                        bad.append(site)
                    else:
                        #print('æœªæœç´¢åˆ°jsæ–‡ä»¶ä¸­çš„urlåœ°å€,ç§»é™¤ï¼š'+str(site['ext']))
                        jsList.remove(site)
                        bad.append(site)
            else:
                #print('è·å–jsæ–‡ä»¶ä¸­çš„urlæ—¶,jsæ–‡ä»¶è¿”å›çš„ä¸æ˜¯code==200 : '+ str(site['ext']))
                jsList.remove(site)
                bad.append(site)
        except Exception as e:  
            #print('è·å–jsæ–‡ä»¶ä¸­çš„urlæ—¶,å‡ºé”™äº†ï¼ˆå¯èƒ½æ˜¯æ²¡æœ‰extæ®µï¼‰ = ' + str(site))
            bad.append(site)
            jsList.remove(site)
        bar.update(1)
    
    def check_url_js(jsList):#æ£€æµ‹jså½±è§†ç½‘ç«™æ˜¯å¦å¯ç”¨,è¿”å›å¯ç”¨çš„æ•°æ®
        print("check_url_js beginï¼")
        goodlist = []
        bad = []
        
        #è¿›åº¦æ¡æ·»åŠ 
        url_list_len = len(jsList)
        print("éœ€è¦æ£€æµ‹çš„sitesä¸ªæ•°ï¼š" + str(url_list_len))
        thread_max_num = threading.Semaphore(64)
        bar = tqdm(total=url_list_len, desc='get iliveï¼š')
        thread_list = []

        for site in jsList[:]:
            try:
                #ä¸ºæ¯ä¸ªURLåˆ›å»ºçº¿ç¨‹
                t = threading.Thread(target=Js.get_ilive_js, args=(site,jsList,bar,goodlist,bad))
                #åŠ å…¥çº¿ç¨‹æ± 
                # åŠ å…¥çº¿ç¨‹æ± å¹¶å¯åŠ¨
                thread_list.append(t)
                t.daemon=True
                t.start()
            except Exception as e: 
                pass
        #ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼Œé…åˆä¸Šé¢çš„t.daemon
        for t in thread_list:
            t.join()
        bar.close() #è¿›åº¦æ¡ç»“æŸ
        
        url_list_len = len(jsList)
        print('æ£€æµ‹å®Œæˆåsitesæ€»æ•°ï¼š'+str(url_list_len))
        
        print('goodæ€»æ•°ï¼š'+str(len(goodlist)))
        print('badæ€»æ•°ï¼š'+str(len(bad)))
        
        #æ¸…ç†é‡å¤
        begin = 0
        rm = 0
        length = len(goodlist)
        print(f'\n-----æ¸…ç†é‡å¤JSå¼€å§‹-----\n')
        while begin < length:
            begin_2 = begin + 1
            while begin_2 <= (length - 1):
                if goodlist[begin]['url'] == goodlist[begin_2]['url']:
                    goodlist.pop(begin_2)
                    length -= 1
                    begin_2 -= 1
                    rm += 1
                begin_2 += 1
            begin += 1
        print(f'é‡å¤æ•°é‡ {rm}\n-----æ¸…ç†é‡å¤JSç»“æŸ-----\n')
        #print(f'å‰©ä½™æ€»æ•° {str(len(goodlist))}\n')
        for site in jsList[:]:
            live = False
            for ilive in goodlist:
                if ilive['name']  == site['name']:
                    live = True
            if live == False:
                jsList.remove(site)
        print(f'jsListå‰©ä½™æ€»æ•° {str(len(jsList))}\n')
        #saveConfig(goodlist,'good.txt')
        return jsList
        
    def get_url_js(key,jsonText):
        newlist =[]
        try:
            #ç”¨jsonæ ¼å¼è½½å…¥æ•°æ®
            config=json5.loads(jsonText)
            #åˆ é™¤æ•°æ®ï¼Œåªç•™ä¸‹è‡ªå·±æƒ³è¦çš„ç”µå½±ç½‘
            i = 0
            for site in config['sites']:
                #print(site)
                try:
                    if '.js' in site['api'] and '.js' in site['ext']:
                        newlist.append(site)
                        i = i + 1
                except Exception as e: 
                    pass
            print(f"{key}æ”¶é›†åˆ°{ str(i) }ä¸ªjs site")
            return newlist
        except Exception as e:  
            print(e)
            return None    

    def fetch_all_js(configList):
        #ç”¨åˆ°çš„ç›®å½•åœ°å€
        api_file = './js.json'
        jar_addr = './jar/js.jar'
        js_addr = './js/'
        js_log_addr = './log/log_js.json'
        libs_addr = './libs/'
        lib_addr = './libs/drpy2.min.js'
        
        #æ›´æ–°libåº“
        Js.down_libs(libs_addr)
        #æ”¶é›†js
        jsList = []
        for key,value in configList.items():
            sites=Js.get_url_js(key,value)
            if sites:
                jsList.extend(sites)#å°†siteså†…å®¹é€ä¸ªåŠ å…¥åˆ—è¡¨
        print(f'æ€»å…±æ”¶é›†åˆ°{str(len(jsList))}ä¸ªjs siteç‚¹')
        
        #è¿‡æ»¤N3rdddç½‘ç«™é‡Œä¸æƒ³è¦çš„JS
        #åˆ é™¤æ•°æ®ï¼Œåªç•™ä¸‹è‡ªå·±æƒ³è¦çš„ç”µå½±ç½‘
        signs = ['[ä¹¦]','[å¬]','[ç›˜]','[çƒ]','[å„¿]','[æ¼«]','[ç”»]','[å¯†]','[é£]','[ç”»å¯†é£]','[å¤®]','[èµ„]','[æœ]','[è‡ªåŠ¨]','ğŸ“€','ç›´æ’­','å¬ä¹¦','éŸ³ä¹','MV','åŠ¨æ¼«','DJ','MV','XVIDEOS','çº¸æ¡','é»‘æ–™','èœ»èœ“FM','ç”µè§† |','å¤¸å…‹ |','å°‘å„¿ |','å¼¹å¹• |','ç›´æ’­ |','ä½“è‚² |','ç›¸å£° |','è¯„ä¹¦ |','æ ¼æ–— |','ç½‘ç›˜ |','åŠ¨æ¼« |','éŸ³é¢‘ |','å¹¿æ’­ |','å¬ä¹¦ |','èšåˆ |','MV |']
        i = 0
        lens = len(jsList)
        print('åŸæ•°æ®sitesä¸ªæ•°ï¼š'+ str(lens))
        for site in jsList[:]:
            for sign in signs:
                if sign in site["name"]:
                    jsList.remove(site)
                    break
        print('è¿‡æ»¤åsitesä¸ªæ•°ï¼š'+ str(len(jsList)))
        #æ£€æµ‹å¯ç”¨çš„JS
        jsList = Js.check_url_js(jsList)
        
        #ä¿®æ”¹é…ç½®å¼€å§‹
        #å…ˆæ‰¾åˆ°jsonæ¨¡æ¿
        try:
            allConfig = json5.loads(configList['n3rddd_js'])
        except KeyError as e:
            print('n3rddd_js no content')
            try:
                allConfig = json5.loads(configList['rx_js'])
            except KeyError as e:
                print('rx no content')
                print('æœ¬æ¬¡æŠ“å–å¤±è´¥jsï¼ŒåŸå› æ˜¯æœ€ç»ˆé…ç½®æ—¶ï¼Œæ‰¾ä¸åˆ°å¯ç”¨çš„jsonæ–‡ä»¶å½“æ¨¡æ¿')
                return 
        #ä¿®æ”¹jaråœ°å€
        #allConfig['spider'] = './n3rddd/js.jar'#ä½¿ç”¨jsçš„jarï¼ŒvodåŸjaræ–‡ä»¶å¤§
        #ä¸‹è½½jaræ–‡ä»¶ï¼Œå¹¶æ”¹åœ°å€ä¸ºæœ¬åœ°åœ°å€
        if 'md5' not in allConfig['spider']:
            response = requests.get(allConfig['spider'])
        else:
            url = re.search(r'(.*);md5;', config['spider']).group(1)
            response = requests.get(url)
        with open(jar_addr, "wb") as f:
            f.write(response.content)
        allConfig['spider'] = jar_addr
        """
        #ä¸‹è½½jaræ–‡ä»¶ï¼Œå¹¶æ”¹åœ°å€ä¸ºæœ¬åœ°åœ°å€
        url = re.search(r'(.*);md5;', config['spider']).group(1)
        response = requests.get(url)
        #jarname = config['spider'].split("/")[-1]
        #jar_addr = all_addr + jarname 
        with open(jar_addr, "wb") as f:
            f.write(response.content)
        config['spider'] = jar_addr
        
        response = requests.get(config['spider'])
        jarname = config['spider'].split("/")[-1]
        jarname = jarname.split(";")[0]
        jar_addr = all_addr + jarname 
        with open(jar_addr, "wb") as f:
            f.write(response.content)
        config['spider'] = './' + jarname
        """
        #æ”¹åå’Œè®¾ç½®å¯ä»¥æœç´¢,ä¸‹è½½jsæ–‡ä»¶
        now = datetime.now()
        nowtime = now.timestamp()
        with open(js_log_addr, "r",encoding='utf-8') as file:
            log_str = file.read()
        log_json = json.loads(log_str)  
        allConfig["sites"] = []#æ¸…ç©ºæ¨¡æ¿siteså†…å®¹
        xuhao = 1
        for site in jsList:#å°†æ£€æµ‹å®Œæˆçš„listæ·»åŠ åˆ°sites
            #æ”¹å
            site['name'] = re.sub(r'é›·è’™|DRPY|å½±è§† [|]','',site['name'])#https://blog.csdn.net/Dontla/article/details/134602233
            site['name'] = re.sub(r'\u00a9|\u00ae|[\u2000-\u3300]|[\ud83c-\ud83e][\ud000-\udfff]|[\s]|[(]|[)]|[|]|-|[0-9]','',site['name'])#emoji å¯¹åº”çš„ç¼–ç åŒºé—´ç”¨æ­£åˆ™è¡¨è¾¾https://blog.csdn.net/wzy0623/article/details/130579863
            site['name'] = str(xuhao)+ '-' + site['name']
            xuhao = xuhao + 1
            #è®¾ç½®å¯ä»¥æœç´¢
            site["searchable"] = 1
            site["quickSearch"] = 1
            
            #åº“æ–‡ä»¶åœ°å€æ”¹æˆæœ¬åœ°åœ°å€
            site['api'] = lib_addr
            #ä¸‹è½½JSæ–‡ä»¶ï¼Œå¹¶æŠŠåœ°å€æ”¹æˆæœ¬åœ°åœ°å€    
            #ç”¨æ³•è¯¦è§£https://blog.csdn.net/jialibang/article/details/84989279
            ## ä»¥/ä¸ºåˆ†éš”ç¬¦ï¼Œä»åé¢åˆ‡1åˆ€
            jsname = site['ext'].split("/")[-1]
            if jsname:
                jsfile_addr = js_addr + jsname
                response = requests.get(site['ext'])
                with open(jsfile_addr, "wb") as f:
                    f.write(response.content)
                site['ext'] = jsfile_addr
                #æŠŠæœªæ·»åŠ åˆ°logçš„jsç½‘ç«™æ·»åŠ è¿›å»
                i = False
                new_dict = {"name":"","æ›´æ–°æ—¶é—´":'',"æ—¶é—´æˆ³":'',"æœ€åæ›´æ–°æ—¶é—´":''}
                for ys in log_json:
                    if jsname in ys['name']:
                        i = True
                        break
                if i ==True:
                    ys['æœ€åæ›´æ–°æ—¶é—´'] = str(now)
                    ys['æ—¶é—´æˆ³'] = nowtime
                else:#ä¸åœ¨logä¸­    
                    new_dict['name'] = jsname
                    new_dict['æ›´æ–°æ—¶é—´'] = str(now)
                    new_dict['æ—¶é—´æˆ³'] = nowtime
                    log_json.append(new_dict)
            #æ·»åŠ åˆ°æ–°sites
            allConfig['sites'].append(site)
        #æŸ¥æ‰¾é•¿æ—¶é—´ä¸èƒ½ç”¨çš„jsæ–‡ä»¶ï¼Œåˆ é™¤
        for ys in log_json:
            sign = False
            for site in allConfig['sites']:
                if ys['name'] in site['ext']:
                    sign = True
                    break
            if sign == False:
                if int(nowtime) - int(ys['æ—¶é—´æˆ³']) > 5270400:#æ–‡ä»¶2ä¸ªæœˆæœªä½¿ç”¨,5270400æ˜¯æ—¶é—´æˆ³ä¸­çš„2ä¸ªæœˆ
                    old_file = js_addr + ys['name']
                    log_json.remove(ys)
                    try:
                        os.remove(old_file)
                    except Exception as e:
                        pass
        #ä¿å­˜jsæ—¥å¿—
        saveConfig(log_json,js_log_addr)

        #æ·»åŠ æ›´æ–°æ—¥æœŸ
        allConfig['sites'][0]['name'] = '[js]' + datetime.today().strftime('%y-%m-%d')
        #ä¿å­˜jsonæ–‡ä»¶
        saveConfig(allConfig,api_file)
        return jsList
        
class Xbpq:#get XBPQ
    def getUrl_signXbpq(url): #æ£€æµ‹ç½‘ç«™æ˜¯å¦å¯ç”¨ï¼ˆå¯åœ¨å…¶ä¸­æ·»åŠ ç”µå½±ç½‘çš„ç‰¹å¾ç ï¼‰,å¯ç”¨è¿”å›False
        signs = ['ç”µå½±','ç”µè§†å‰§','è¿ç»­å‰§','å‰§åœº','éŸ©å‰§','ç»¼è‰º','åŠ¨æ¼«','ç¾å‰§','çƒ­æ’­','ä¸Šæ˜ ','å›½äº§','æ¸¯å°','é›»å½±','é›»è¦–åŠ‡','ç¶œè—','å‹•æ¼«']
        try:
            r=requests.get(url, timeout=5.0)
            if r.status_code==200:
                #return False
                for sign in signs:
                    if sign in r.text:
                        return False
                return True
            else:
                return True
        except Exception as e: 
            return True

    def get_ailve_XBPQ(site,config,bar):
        try:
            if Xbpq.getUrl_signXbpq(site['ext']['ä¸»é¡µurl']):
                config.remove(site)
        #except Exception as e:#ä¸‡èƒ½å¼‚å¸¸
        except KeyError as e:#æ²¡æœ‰å…³é”®å­—
            #print('no url' + site['name'])
            config.remove(site)
        except Exception as e:
            config.remove(site)
        bar.update(1)

    def check_url_XBPQ(xbpqList):  
        #ç”¨jsonæ ¼å¼è½½å…¥æ•°æ®
        #xbpqList=json5.loads(xbpqList)   #æœ¬åœ°ä¸ç”¨æ‰“å¼€,githubä¸Š æ‰“å¼€
        url_list_len = len(xbpqList)
        print("éœ€è¦æ£€æµ‹çš„XBPQ sitesä¸ªæ•°ï¼š" + str(url_list_len))
        thread_max_num = threading.Semaphore(64)
        bar = tqdm(total=url_list_len, desc='get iliveï¼š')
        thread_list = []

        for site in xbpqList[:]:
            try:
                #ä¸ºæ¯ä¸ªURLåˆ›å»ºçº¿ç¨‹
                t = threading.Thread(target=Xbpq.get_ailve_XBPQ, args=(site,xbpqList,bar))
                #åŠ å…¥çº¿ç¨‹æ± 
                # åŠ å…¥çº¿ç¨‹æ± å¹¶å¯åŠ¨
                thread_list.append(t)
                t.daemon=True
                t.start()
            except Exception as e: 
                #bar.update(1)
                pass
        #ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼Œé…åˆä¸Šé¢çš„t.daemon
        for t in thread_list:
            t.join()
        bar.close() #è¿›åº¦æ¡ç»“æŸ
        
        url_list_len = len(xbpqList)
        print("æ£€æµ‹å®Œæˆçš„XBPQ sitesä¸ªæ•°ï¼š" + str(url_list_len))
        return xbpqList
    
    def get_url_xbpq(key,jsonText):
        newlist =[]
        try:
            #ç”¨jsonæ ¼å¼è½½å…¥æ•°æ®
            config=json5.loads(jsonText)
            #åˆ é™¤æ•°æ®ï¼Œåªç•™ä¸‹è‡ªå·±æƒ³è¦çš„ç”µå½±ç½‘
            i = 0
            for site in config['sites']:
                #print(site)
                if 'XBPQ' in site['api'] or 'xbpq' in site['api']:
                    newlist.append(site)
                    i = i + 1
            print(f"{key}æ”¶é›†åˆ°{ str(i) }ä¸ªxbpq site")
            return newlist
        except Exception as e:  
            print(e)
            return None    
            
    def fetch_all_xbpq(configList):
        xbpqList = []
        for key,value in configList.items():
            sites=Xbpq.get_url_xbpq(key,value)
            if sites:
                xbpqList.extend(sites)#å°†url_vodå†…å®¹é€ä¸ªåŠ å…¥åˆ—è¡¨
        print(f'æ€»å…±æ”¶é›†åˆ°{str(len(xbpqList))}ä¸ªxbpq siteç‚¹')
        #æ£€æµ‹æ˜¯å¦å¯ç”¨
        xbpqList = Xbpq.check_url_XBPQ(xbpqList)
        #ä¿®æ”¹é…ç½®å¼€å§‹
        #å…ˆæ‰¾åˆ°jsonæ¨¡æ¿
        try:
            allConfig = json5.loads(configList['n3rddd_js'])
        except KeyError as e:
            print('n3rddd_js no content')
            try:
                allConfig = json5.loads(configList['rx_js'])
            except KeyError as e:
                print('rx no content')
                print('æœ¬æ¬¡æŠ“å–å¤±è´¥xbpqï¼ŒåŸå› æ˜¯æœ€ç»ˆé…ç½®æ—¶ï¼Œæ‰¾ä¸åˆ°å¯ç”¨çš„jsonæ–‡ä»¶å½“æ¨¡æ¿')
                return 
        #ä¿®æ”¹jaråœ°å€
        allConfig['spider'] = './jar/js.jar'#ä½¿ç”¨jsçš„jarï¼ŒvodåŸjaræ–‡ä»¶å¤§
        #æ”¹åå’Œè®¾ç½®å¯ä»¥æœç´¢
        allConfig["sites"] = []#æ¸…ç©ºæ¨¡æ¿siteså†…å®¹
        xuhao = 1
        for site in xbpqList:#å°†æ£€æµ‹å®Œæˆçš„listæ·»åŠ åˆ°sites
            #æ”¹å
            site['name'] = re.sub(r'é›·è’™|DRPY|å½±è§† [|]','',site['name'])#https://blog.csdn.net/Dontla/article/details/134602233
            site['name'] = re.sub(r'\u00a9|\u00ae|[\u2000-\u3300]|[\ud83c-\ud83e][\ud000-\udfff]|[\s]|[(]|[)]|[|]|-|[0-9]','',site['name'])#emoji å¯¹åº”çš„ç¼–ç åŒºé—´ç”¨æ­£åˆ™è¡¨è¾¾https://blog.csdn.net/wzy0623/article/details/130579863
            site['name'] = str(xuhao)+ '-' + site['name']
            xuhao = xuhao + 1
            #è®¾ç½®å¯ä»¥æœç´¢
            site["searchable"] = 1
            site["quickSearch"] = 1
            allConfig['sites'].append(site)

        #æ·»åŠ æ›´æ–°æ—¥æœŸ
        allConfig['sites'][0]['name'] = '[xbpq]' + datetime.today().strftime('%y-%m-%d')
        #ä¿å­˜jsonæ–‡ä»¶
        saveConfig(allConfig,'xbpq.json')
        return xbpqList

class Vod: #get vod
    def getUrl_signVod(url): #æ£€æµ‹ç½‘ç«™æ˜¯å¦å¯ç”¨ï¼ˆå¯åœ¨å…¶ä¸­æ·»åŠ ç”µå½±ç½‘çš„ç‰¹å¾ç ï¼‰,å¯ç”¨è¿”å›False
        try:
            r=requests.get(url, timeout=3.0)
            if r.status_code==200:
                #provide/vod
                if 'provide/vod' in url:
                    host = re.findall("(.*?)/provide/vod", url)
                    if host:
                        newurl = host[0] + '/provide/vod/' + '?wd=1'  #æ·»åŠ æœç´¢ä»£ç 
                        r1=requests.get(newurl, timeout=3.0)
                        if r != r1:
                            try:
                                r1json = json5.loads(r1.text)
                                if '1' in r1json['list'][0]['vod_name']:
                                    return False
                            except Exception as e:  
                                pass
                elif 'api.php' in url:#ä¸æ˜¯æ ‡å‡†çš„provide/vod
                    newurl = url + '?wd=1'  #æ·»åŠ æœç´¢ä»£ç 
                    r1=requests.get(newurl, timeout=3.0)
                    if r != r1:
                        try:
                            r1json = json5.loads(r1.text)
                            if '1' in r1json['list'][0]['vod_name']:
                                return False
                        except Exception as e:  
                            pass
                elif '.php' in url.split("/")[-1]:#T4å¯ç”¨ç«™
                    signs = ['{"code":1','å½±è§†','ç”µå½±','è¿ç»­å‰§','ç»¼è‰º','åŠ¨æ¼«']
                    for sign in signs:
                        if sign in r.text:
                            return False
            return True
        except Exception as e: 
            return True
            
    def get_ilive_vod(site,jsconfig,bar,goodlist,bad):
        if Vod.getUrl_signVod(site['api']):
            jsconfig.remove(site)
        bar.update(1)
            
    def check_url_vod(vodList):
        print("check_vod_url beginï¼")
        goodlist = []
        bad = []
        
        #å¯ç”¨æµ‹è¯•,è¿›åº¦æ¡æ·»åŠ 
        #jsconfig=json5.loads(vodList)
        url_list_len = len(vodList)
        print("vodéœ€è¦æ£€æµ‹çš„sitesä¸ªæ•°ï¼š" + str(url_list_len))
        thread_max_num = threading.Semaphore(64)
        bar = tqdm(total=url_list_len, desc='get iliveï¼š')
        thread_list = []
        for site in vodList[:]:
            try:
                #ä¸ºæ¯ä¸ªURLåˆ›å»ºçº¿ç¨‹
                t = threading.Thread(target=Vod.get_ilive_vod, args=(site,vodList,bar,goodlist,bad))
                #åŠ å…¥çº¿ç¨‹æ± 
                # åŠ å…¥çº¿ç¨‹æ± å¹¶å¯åŠ¨
                thread_list.append(t)
                t.daemon=True
                t.start()
            except Exception as e: 
                #bar.update(1)
                pass
        #ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼Œé…åˆä¸Šé¢çš„t.daemon
        for t in thread_list:
            t.join()
        bar.close() #è¿›åº¦æ¡ç»“æŸ
        
        url_list_len = len(vodList)
        print('vodæ£€æµ‹å®Œæˆåsitesæ€»æ•°ï¼š'+str(url_list_len))
        
        #print('goodæ€»æ•°ï¼š'+str(len(goodlist)))
        #print('badæ€»æ•°ï¼š'+str(len(bad)))
        #saveList(goodlist,'good.txt')
        return vodList

    def get_url_vod(key,jsonText):
        newlist =[]
        try:
            #ç”¨jsonæ ¼å¼è½½å…¥æ•°æ®
            config=json5.loads(jsonText)
            #åˆ é™¤æ•°æ®ï¼Œåªç•™ä¸‹è‡ªå·±æƒ³è¦çš„ç”µå½±ç½‘
            i = 0
            for site in config['sites']:
                #print(site)
                if '/vod' in site['api'] or '.php' in site['api']:
                    newlist.append(site)
                    #print(site['api'])
                    i = i + 1
            print(f"{key}æ”¶é›†åˆ°{ str(i) }ä¸ªvod site")
            return newlist
        except Exception as e:  
            print(e)
            return None     
            
    def fetch_all_vod(configList):
        vodList = []
        for key,value in configList.items():
            sites=Vod.get_url_vod(key,value)
            if sites:
                vodList.extend(sites)#å°†siteså†…å®¹é€ä¸ªåŠ å…¥åˆ—è¡¨
        
        #è·å–hikeræŠ“åˆ°çš„listï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
        r = requests.get('https://rxsub.eu.org/hiker/api/api_good.txt')
        vodurllist = re.split(r'\n+',r.text)
        print("hiker vod list åŸä¸ªæ•°ï¼š" + str(len(vodurllist)))
        for site in vodList:
            i = 0
            l = len(vodurllist)
            while i<l:
                if vodurllist[i] in site['api']:
                    #site['api'] = vodurllist[i]
                    vodurllist.pop(i)
                    l -= 1
                    i -= 1
                i += 1    
        print("hiker vod list åˆ é™¤å®Œåä¸ªæ•°ï¼š" + str(len(vodurllist)))
        #æŠŠå‰©ä½™çš„æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        i=1
        for url in vodurllist:
            newurl = {"key": "","name": "","type": 1,"api": "","searchable": 1,"quickSearch": 1}
            newurl['key'] = 'hiker-'+ str(i)
            newurl['name'] = 'hiker-'+ str(i)
            newurl['api'] = url
            vodList.append(newurl)
            i += 1
        print(f'æ€»å…±æ”¶é›†åˆ°{str(len(vodList))}ä¸ªvod siteç‚¹')
        
        #å»é‡å¼€å§‹
        begin = 0
        rm = 0
        length = len(vodList)
        print(f'\n-----apiå»é‡å¼€å§‹-----\n')
        while begin < length:
            proxy_compared = vodList[begin]
            begin_2 = begin + 1
            while begin_2 <= (length - 1):
                if proxy_compared['api'] == vodList[begin_2]['api']:
                    vodList.pop(begin_2)
                    length -= 1
                    begin_2 -= 1
                    rm += 1
                begin_2 += 1
            begin += 1
        print(f'vod_apié‡å¤æ•°é‡ {rm}\n-----å»é‡ç»“æŸ-----\n')
        print(f'å»é‡åæ€»æ•° {str(len(vodList))}\n')
        
        #æ£€æµ‹vodç½‘ç«™
        vodList = Vod.check_url_vod(vodList)
        
        #æŸ¥æ‰¾é‡å¤ç½‘å€+é‡å¤keyé‡å‘½å
        begin = 0
        rm = 0
        length = len(vodList)
        print(f'\n-----æŸ¥æ‰¾é‡å¤ç½‘å€-----\n')
        while begin < length:
            proxy_compared = vodList[begin]
            begin_2 = begin + 1
            rmname = 1
            while begin_2 <= (length - 1):
                if proxy_compared['api'] in vodList[begin_2]['api'] or vodList[begin_2]['api'] in proxy_compared['api']:
                    vodList.pop(begin_2)
                    length -= 1
                    begin_2 -= 1
                    rm += 1
                #elif proxy_compared['key'] == vodList[begin_2]['key'] or proxy_compared['key'] in vodList[begin_2]['key'] or vodList[begin_2]['key'] in proxy_compared['key']:
                elif proxy_compared['key'] == vodList[begin_2]['key']:
                    vodList[begin_2]['key'] = vodList[begin_2]['key'] + str(rmname)
                    rmname = rmname + 1
                begin_2 += 1
            begin += 1
        print(f'vodé‡å¤ç½‘å€æ•°é‡ {rm}\n-----å»é‡ç»“æŸ-----\n')
        print(f'å»é‡åæ€»æ•° {str(len(vodList))}\n')

        
        #ä¿®æ”¹é…ç½®å¼€å§‹
        #å…ˆæ‰¾åˆ°jsonæ¨¡æ¿
        try:
            allConfig = json5.loads(configList['n3rddd_js'])
        except KeyError as e:
            print('n3rddd no content')
            try:
                allConfig = json5.loads(configList['rx_js'])
            except KeyError as e:
                print('rx no content')
                print('æœ¬æ¬¡æŠ“å–å¤±è´¥vodï¼ŒåŸå› æ˜¯æœ€ç»ˆé…ç½®æ˜¯ï¼Œæ‰¾ä¸åˆ°å¯ç”¨çš„jsonæ–‡ä»¶å½“æ¨¡æ¿')
                return 
        
        #æ”¹åå’Œè®¾ç½®å¯ä»¥æœç´¢
        allConfig["sites"] = []#æ¸…ç©ºæ¨¡æ¿siteså†…å®¹
        xuhao = 1
        for site in vodList:#å°†æ£€æµ‹å®Œæˆçš„listæ·»åŠ åˆ°sites
            #æ”¹å
            site['name'] = re.sub(r'é›·è’™|DRPY|å½±è§† [|]','',site['name'])#https://blog.csdn.net/Dontla/article/details/134602233
            site['name'] = re.sub(r'\u00a9|\u00ae|[\u2000-\u3300]|[\ud83c-\ud83e][\ud000-\udfff]|[\s]|[(]|[)]|[|]|-|[0-9]','',site['name'])#emoji å¯¹åº”çš„ç¼–ç åŒºé—´ç”¨æ­£åˆ™è¡¨è¾¾https://blog.csdn.net/wzy0623/article/details/130579863
            site['name'] = str(xuhao)+ '-' + site['name']
            xuhao = xuhao + 1
            #è®¾ç½®å¯ä»¥æœç´¢
            site["searchable"] = 1
            site["quickSearch"] = 1
            allConfig['sites'].append(site)
        
        #ä¿®æ”¹jaråœ°å€
        #allConfig['spider'] = './jar/js.jar'#ä½¿ç”¨jsçš„jarï¼ŒvodåŸjaræ–‡ä»¶å¤§
        allConfig['spider'] = './jar/bili.jar'#bili.jaråªæœ‰90kb
        #æ·»åŠ æ›´æ–°æ—¥æœŸ
        allConfig['sites'][0]['name'] = '[vod]' + datetime.today().strftime('%y-%m-%d')
        #ä¿å­˜jsonæ–‡ä»¶
        saveConfig(allConfig,'vod.json')
        
        #æ·»åŠ å„¿ç«¥ä¹å›­
        babyConfig = {}
        babyConfig['spider'] = './jar/bilibili.jar'#å„¿ç«¥ä¹å›­ä½¿ç”¨
        babyConfig["logo"] = allConfig["logo"]
        babyConfig["wallpaper"] = allConfig["wallpaper"]
        babyConfig["sites"] = allConfig['sites']
        babyConfig["sites"].insert(1,rx)#åœ¨ä»»æ„ä½ç½®æ·»åŠ æ•°æ®
        babyConfig["lives"] = allConfig["lives"]
        saveConfig(babyConfig,'baby.json')
        
        #æ›´æ–°åˆ°ç½‘ç›˜


        return vodList

class GUC:#get url config
    def setParise(customConfig,configList):#diy è§£ææœªå¼€å‘
        print('è®¾ç½®è§£æå¼€å§‹')
        # if customConfig :
        #   # æå–è§£æparses
        #   parses=[]
        #   if 'é¦™é›…æƒ…' in configList and not parses:
        #     parses=configList['é¦™é›…æƒ…']['parses']
        #     customConfig['parses']=parses
        #   if 'OKä½¬' in configList and not parses:
        #     parses=configList['OKä½¬']['parses']
        #     customConfig['parses']=parses
        print('è®¾ç½®è§£æç»“æŸ')
     
    def encodeBase64(content):#diy lives é‡Œé¢ä½¿ç”¨çš„
        content='**'+base64.b64encode(content.encode('utf-8')).decode('utf-8')
        print(content)
        return content 

    def supplementAddr(url,config):# è¡¥å……ç›¸å¯¹åœ°å€
        
        host =url[:url.rfind('/')]
        #print('host:',host)
        pattern=r'"\./.*?"'
        config=re.sub(pattern,lambda x:"\""+host+x.group(0)[2:],config)
        #result=re.findall(pattern,config)
        #print(config)
        return config

    def isJson(content):#æ£€æµ‹æ˜¯å¦æ˜¯Json5æ•°æ®å†…å®¹
        try:
            data=json5.loads(content)
            return True
        except Exception as e:  
            return False
      
    def FindResult(content,key=None):#æ‰¾åˆ°jsonæ–‡ä»¶å†…å®¹

      # è§£æåŠ å¯† ä»¥8ä¸ªå­—æ¯åŠ **çš„å†…å®¹
      pattern = re.compile(r"[A-Za-z0]{8}\*\*")
      result = pattern.search(content) 
      if result:
        try:
            #print(result.group())
            #print(content.index(result.group()))
            content = content[content.index(result.group()) + 10:]
            data=base64.b64decode(content).decode('utf-8')
            #print(data)
            return data
        except Exception as e:
          return None
        
      # è§£æ ä»¥**å¼€å¤´çš„å†…å®¹ ä¸»è¦åœ¨livesé…ç½®åŠ å¯†ä¸­
      if content.startswith('**'):
        try:
            #print(result.group())
            #print(content.index(result.group()))
            content = content[2:]
            data=base64.b64decode(content).decode('utf-8')
            #print(data)
            return data
        except Exception as e:
          return None
        
      # è§£æ ä»¥2423å¼€å¤´çš„å†…å®¹
      if content.startswith('2423'):
            return '2423å¼€å¤´å†…å®¹å°šæœ«è§£æ'
      
      # æ”¾åé¢ä¸»è¦é˜²æ­¢ä¸æ˜¯jsonçš„ä¸ºåˆ¤æ–­ä¸ºjson
      if GUC.isJson(content):
        #print('========= is json5')
        return content
      
      elif key and GUC.isJson(content):
        try:
          aes = AES.new(key,AES.MODE_ECB)
          data=aes.decrypt(content)
          return data
        except Exception as e:
          return None
      
      else:
        #return 'æ— æ³•è§£æå†…å®¹'
        return None

    def getConfig(key,value,configList,bar):#è·å–ç½‘ç«™çš„jsonå†…å®¹ï¼Œå°†è·å–çš„configè¿”å›
        headers={
        "User-Agent":"okhttp/3.15",
        "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"
        }
        try:
            r=requests.get(value,headers=headers, timeout=3.0)
            if r.status_code==200:
                r.encoding='utf-8'    #ç¼–ç æ–¹å¼
                jsonText=GUC.FindResult(r.text,'')
                #print(jsonText)
            if jsonText:
                jsonText = GUC.supplementAddr(value,jsonText)#æ·»åŠ æ–‡ä»¶çš„ç›¸å¯¹åœ°å€
                #return jsonText
                configList[key]=jsonText
        except requests.exceptions.RequestException as e:  
            print(e)
        except Exception as e: 
            pass
            print(f'è·å–å†…å®¹å¤±è´¥ï¼š{value}')
        bar.update(1)
        
    def getConfigs(list):#è·å–åˆ—è¡¨ç½‘ç«™çš„jsonå†…å®¹ï¼Œå°†è·å–çš„å†…å®¹å­˜å…¥åˆ—è¡¨configListè¿”å›
        print('å¼€å§‹æ”¶é›†ç½‘ç«™jsonï¼š' + str(datetime.now()))
        configList={}
        """
        for key,value in list.items():
            config=GUC.getConfig(value)
            if config:
                configList[key]=config
        return configList
        """
        #è¿›åº¦æ¡æ·»åŠ 
        list1=list
        url_list_len = len(list1.items())
        thread_max_num = threading.Semaphore(64)
        bar = tqdm(total=url_list_len, desc='fetch json:')
        thread_list = []
        for key,value in list.items():
            try:
                #ä¸ºæ¯ä¸ªURLåˆ›å»ºçº¿ç¨‹
                t = threading.Thread(target=GUC.getConfig, args=(key,value,configList,bar))
                #åŠ å…¥çº¿ç¨‹æ± 
                # åŠ å…¥çº¿ç¨‹æ± å¹¶å¯åŠ¨
                thread_list.append(t)
                t.daemon=True
                t.start()
            except Exception as e: 
                #bar.update(1)
                pass
        #ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼Œé…åˆä¸Šé¢çš„t.daemon
        for t in thread_list:
            t.join()
        bar.close() #è¿›åº¦æ¡ç»“æŸ
        print('æ”¶é›†ç½‘ç«™jsonç»“æŸï¼š' + str(datetime.now()))
        return configList
        

def diy_fan(configList):
    #é¥­å¤ªç¡¬é…ç½®
    md5_addr = "./log/md5.ini"
    #my_fan_url = r'http://4901.kstore.space/fan.txt'
    my_fan_url = r'http://d.kstore.dev/download/4901/tvbox/jar/fan.jar'
    fan_json_addr = './fan.json'
    fan_jar_addr = './jar/fan.jar'
    #rx = {"key": "å„¿ç«¥ä¹å›­","name": "å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","playerType":1,"ext": "http://4901.kstore.space/å„¿ç«¥ä¹å›­.json"}
    #rx = {"key": "å„¿ç«¥ä¹å›­","name": "å„¿ç«¥ä¹å›­","type": 3,"api": "csp_Bili","playerType": 1,"ext": {"json": "http://4901.kstore.space/å„¿ç«¥ä¹å›­.json"}}
    rx_fan = {"key": "å„¿ç«¥ä¹å›­","name": "å„¿ç«¥ä¹å›­","type": 3,"api": "csp_Bili","searchable":0,"quickSearch":0,"filterable":1,"ext": {"json": "http://d.kstore.dev/download/4901/tvbox/json/å„¿ç«¥ä¹å›­fan.json"}}
    #rx = {"key":"å„¿ç«¥ä¹å›­","name":"å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","style":{"type":"rect","ratio":1.597},"searchable":0,"quickSearch":0,"changeable":0,"filterable":1,"ext":{"json":"http://d.kstore.dev/download/4901/å„¿ç«¥ä¹å›­fan.json"}}
    #rx = {"key": "å„¿ç«¥ä¹å›­","name": "å„¿ç«¥ä¹å›­","type": 3,"api": "csp_Bili","searchable":0,"quickSearch":0,"filterable":1,"ext": {"json": "http://4901.kstore.space/å„¿ç«¥ä¹å›­.json"}}
    #ä½¿ç”¨ä¸Šé¢ç®€åŒ–çš„ç”µè§†ä¸Šæ‰èƒ½æ’­æ”¾

    #å¦‚æœæœªè·å–åˆ°fançš„å†…å®¹
    if 'fan' not in configList:
        print('fan' + ' : KeyError_åº”è¯¥æ˜¯ç½‘å€å˜äº†ï¼Œæ²¡è·å–åˆ°æœ€æ–°çš„jsonæ•°æ®,å»æ‰¾æœ€æ–°æ¥å£åœ°å€ï¼')
        #å†™å…¥é”™è¯¯æ—¥å¿—
        file = open("./log/log.txt", "a")
        file.write('\n' + str(datetime.now()) + ' : ' + 'fan' + ' : KeyError_åº”è¯¥æ˜¯ç½‘å€å˜äº†ï¼Œæ²¡è·å–åˆ°æœ€æ–°çš„jsonæ•°æ®,å»æ‰¾æœ€æ–°æ¥å£åœ°å€ï¼')
        file.close()
        return
    #å¼€å§‹DIY
    print('hello,é¥­å¤ªç¡¬!')
    config = configparser.ConfigParser()
    config.read(md5_addr)
    m = hashlib.md5()
    str_json = str(configList['fan'])
    m.update(str_json.encode('utf-8'))
    md5 = m.hexdigest()

    try:
        old_md5 = config.get("fan_md5", "conf")
        if md5 == old_md5:
            print("No update needed")
            return
    except:
        pass
    
    # Update md5.conf
    config.set("fan_md5", "conf", md5)
    with open(md5_addr, "w") as f:
        config.write(f)
 
    #å°†æ•°æ®è½¬æˆjson5æ ¼å¼
    json_format = json5.loads(configList['fan'])
    #è·å–jaråœ°å€å’Œmd5
    content = json_format["spider"]
    url = re.search(r'(.*);md5;', content).group(1)
    jmd5 = re.search(r';md5;(\w+)', content).group(1)
    #å¯¹æ¯”jarçš„md5ï¼Œä¸åŒå°±å°†æ›´æ–°md5å’Œjar
    current_md5 = config.get("fan_md5", "jar").strip()
    if jmd5 != current_md5:
        # Update md5
        config.set("fan_md5", "jar", jmd5)
        with open(md5_addr, "w") as f:
            config.write(f)
        # Update jar
        response = requests.get(url)
        with open(fan_jar_addr, "wb") as f:
            f.write(response.content)
    
    ####diyä¿®æ”¹jsonå†…å®¹#############ï¼š
    
    #ä¿®æ”¹jarçš„æ–°åœ°å€
    content = re.sub(url, my_fan_url, content)
    json_format["spider"] = content
    
    #å¢åŠ ä¿®æ”¹æ—¶é—´,æ·»åŠ å„¿ç«¥ä¹å›­
    json_format["sites"][0]['name'] = '[é¥­]' + datetime.today().strftime('%y-%m-%d')
    json_format["sites"].insert(1,rx_fan)#åœ¨ä»»æ„ä½ç½®æ·»åŠ æ•°æ®
    #json_format["sites"].append(rx)#åœ¨æœ«å°¾è¿½åŠ æ•°æ®
    """
    try:
        with open('vod.json', "r",encoding='utf-8') as file:
            vod_str = file.read()
            vod_json = json.loads(vod_str)
        #popå¯ç”¨åˆ é™¤åˆ—è¡¨ç¬¬ä¸€æ¡å¸¦æ—¥æœŸçš„
        #vod_json["sites"].pop(0)
        json_format["sites"].extend(vod_json["sites"])
    except Exception as e:
        print(e)
        print("æ·»åŠ vod sitesæ—¶ï¼Œå‡ºç°çš„é”™è¯¯ï¼")
        pass
    """
    #ä¿å­˜jsonæ–‡ä»¶
    saveConfig(json_format,fan_json_addr)
    #æ›´æ–°åˆ°ç½‘ç›˜


def diy_feimao(configList):
    #è‚¥çŒ«é…ç½®
    md5_addr = "./log/md5.ini"
    my_feimao_url = r'http://d.kstore.dev/download/4901/tvbox/jar/feimao.jar'
    feimao_json_addr = './feimao.json'
    feimao_jar_addr = './jar/feimao.jar'  
    #rx = {"key": "å„¿ç«¥ä¹å›­","name": "å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","playerType":1,"ext": "http://4901.kstore.space/å„¿ç«¥ä¹å›­.json"}
    rx_feimao = {"key":"å„¿ç«¥ä¹å›­","name":"å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","searchable":0,"quickSearch":0,"changeable":0,"ext": "./json/å„¿ç«¥ä¹å›­.json"}
    #ä½¿ç”¨ä¸Šé¢ç®€åŒ–çš„ç”µè§†ä¸Šæ‰èƒ½æ’­æ”¾
    #rx = {"key":"å„¿ç«¥ä¹å›­","name":"å„¿ç«¥ä¹å›­","type":3,"api":"csp_Bili","searchable":0,"quickSearch":0,"filterable":1,"ext":"http://4901.kstore.space/å„¿ç«¥ä¹å›­.json"}

    #å¦‚æœæœªè·å–åˆ°feimaoçš„å†…å®¹
    if 'feimao' not in configList:
        print('feimao' + ' : KeyError_åº”è¯¥æ˜¯ç½‘å€å˜äº†ï¼Œæ²¡è·å–åˆ°æœ€æ–°çš„jsonæ•°æ®,å»æ‰¾æœ€æ–°æ¥å£åœ°å€ï¼')
        #å†™å…¥é”™è¯¯æ—¥å¿—
        file = open("./log/log.txt", "a")
        file.write('\n' + str(datetime.now()) + ' : ' + 'feimao' + ' : KeyError_åº”è¯¥æ˜¯ç½‘å€å˜äº†ï¼Œæ²¡è·å–åˆ°æœ€æ–°çš„jsonæ•°æ®,å»æ‰¾æœ€æ–°æ¥å£åœ°å€ï¼')
        file.close()
        return
    #å¼€å§‹DIY
    print('hello,è‚¥çŒ«!')
    config = configparser.ConfigParser()
    config.read(md5_addr)
    m = hashlib.md5()
    str_json = str(configList['feimao'])
    m.update(str_json.encode('utf-8'))
    md5 = m.hexdigest()

    try:
        old_md5 = config.get("feimao_md5", "conf")
        if md5 == old_md5:
            print("No update needed")
            return
    except:
        pass
    # Update md5.conf
    config.set("feimao_md5", "conf", md5)
    with open(md5_addr, "w") as f:
        config.write(f)
 
    #å°†æ•°æ®è½¬æˆjson5æ ¼å¼
    json_format = json5.loads(configList['feimao'])
    #è·å–jaråœ°å€å’Œmd5
    content = json_format["spider"]
    url = re.search(r'(.*);md5;', content).group(1)
    jmd5 = re.search(r';md5;(\w+)', content).group(1)
    #å¯¹æ¯”jarçš„md5ï¼Œä¸åŒå°±å°†æ›´æ–°md5å’Œjar
    current_md5 = config.get("feimao_md5", "jar").strip()
    if jmd5 != current_md5:
        # Update md5
        config.set("feimao_md5", "jar", jmd5)
        with open(md5_addr, "w") as f:
            config.write(f)
        # Update jar
        response = requests.get(url)
        with open(feimao_jar_addr, "wb") as f:
            f.write(response.content)
    
    ####diyä¿®æ”¹jsonå†…å®¹#############ï¼š
    
    #ä¿®æ”¹jarçš„æ–°åœ°å€ - è‚¥çŒ«çš„ä¿®æ”¹åå‡ºç°å½±è§†æ¥å£é—®é¢˜ï¼Œå…ˆä¸ä¿®æ”¹
    content = re.sub(url, my_feimao_url, content)
    json_format["spider"] = content
    
    #å¢åŠ ä¿®æ”¹æ—¶é—´,æ·»åŠ å„¿ç«¥ä¹å›­
    json_format["sites"][0]['name'] = '[è‚¥çŒ«]' + datetime.today().strftime('%y-%m-%d')
    json_format["sites"].insert(1,rx_feimao)#åœ¨ä»»æ„ä½ç½®æ·»åŠ æ•°æ®
    #json_format["sites"].append(rx)#åœ¨æœ«å°¾è¿½åŠ æ•°æ®
    """
    try:
        with open('vod.json', "r",encoding='utf-8') as file:
            vod_str = file.read()
            vod_json = json.loads(vod_str)  
        json_format["sites"].extend(vod_json["sites"])
    except Exception as e:
        print(e)
        print("æ·»åŠ vod sitesæ—¶ï¼Œå‡ºç°çš„é”™è¯¯ï¼")
        pass
    """
    #ä¿å­˜jsonæ–‡ä»¶
    saveConfig(json_format,feimao_json_addr)

if "__name__==__main__":#ä¸»ç¨‹åºå¼€å§‹
    configList=GUC.getConfigs(list)
    #customConfig=setConfig(configList)
    #setLives(customConfig,configList)
    #setPariseè¿˜æœªå¼€å‘
    #setParise(customConfig,configList)

    #è·å–æ•°æ®
    Vod.fetch_all_vod(configList)
    Js.fetch_all_js(configList)
    #Xbpq.fetch_all_xbpq(configList)
    diy_fan(configList)
    diy_feimao(configList)

    """
    #è·å–n3rdddç½‘å€æ•°æ®
    if configList['n3rddd']:
        get_github_n3rddd(configList['n3rddd'])
    else:
        print("æœªè·å–åˆ°ç½‘å€jsonæ•°æ®:" + list['n3rddd'])
    #è·å–gaotianliuyunç½‘å€æ•°æ®
    if configList['gao']:
        get_github_gao(configList['gao'])
    else:
        print("æœªè·å–åˆ°ç½‘å€jsonæ•°æ®:" + list['gaotianliuyun'])
    """
    
    
